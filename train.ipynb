{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c40e0718-5975-4216-98a2-f9b8f8a94503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bfad29b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T04:58:08.724484Z",
     "start_time": "2023-03-02T04:58:08.145009Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8de33276-12f7-4995-bf62-f4942035363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -q images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a97c7cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T04:58:10.076531Z",
     "start_time": "2023-03-02T04:58:08.726544Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 11:19:29.005950: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, InputLayer, LeakyReLU, Input, concatenate, AveragePooling1D, Reshape, ReLU, ZeroPadding1D,Bidirectional\n",
    "from tensorflow.keras.layers import LSTM, GRU, Conv1D, MaxPooling1D, Flatten, Dropout, LayerNormalization, SpatialDropout1D, Concatenate, Add, TimeDistributed, ReLU\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from tensorflow.keras.initializers import HeNormal, HeUniform\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b72b59c6-1a3e-4f6b-856c-e7b7391c56c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "\n",
    "class Epochs(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if((int(epoch+1) % 5) == 0) or (epoch == 0) :\n",
    "              print(f\"Epoch {epoch+1} \\n  Loss: {np.round(logs['loss'],5)}\") #     val_loss:  {np.round(logs['val_loss'],3)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b32bc589",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T04:58:10.760400Z",
     "start_time": "2023-03-02T04:58:10.083080Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 11:19:30.724298: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-16 11:19:30.726732: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: \n"
     ]
    }
   ],
   "source": [
    "time_step = 224\n",
    "def lc_block(filters, x):\n",
    "  x = Conv1D(filters = filters, kernel_size = 3)(x)\n",
    "  x = LayerNormalization()(x)\n",
    "  x = LeakyReLU(0.05)(x)\n",
    "  x = LSTM(filters, return_sequences = True)(x)\n",
    "  x = LayerNormalization()(x)\n",
    "  x = Conv1D(filters = filters, kernel_size = 3)(x)\n",
    "  x = LayerNormalization()(x)\n",
    "  x = ReLU()(x)\n",
    "  return x\n",
    "\n",
    "# MODEL ARCHITECTURE\n",
    "input_layer = Input(shape=(time_step, 1))\n",
    "x = input_layer\n",
    "x = lc_block(128, x)\n",
    "x = lc_block(256, x)\n",
    "x = MaxPooling1D(pool_size = 2, strides = 2)(x)\n",
    "x = lc_block(128, x)\n",
    "x = lc_block(256, x)\n",
    "x = MaxPooling1D(pool_size = 2, strides = 1)(x)\n",
    "x = lc_block(64, x)\n",
    "x = MaxPooling1D(pool_size = 2, strides = 1)(x)\n",
    "x = Flatten()(x)\n",
    "x = BatchNormalization()(x)\n",
    "output_layer = Dense(1, )(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# model.compile(loss='mean_squared_error', optimizer = RMSprop(learning_rate = 0.002))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ebf3c4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T04:58:11.010591Z",
     "start_time": "2023-03-02T04:58:10.761448Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(1,8))\n",
    "points = np.empty((0,2))\n",
    "start_point = -1\n",
    "time_step = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e1b6089-9721-4122-a8c1-f53beae78c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_layer = Input(shape=(time_step, 1))\n",
    "# x = Conv1D(filters=128, kernel_size = 5)(input_layer)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = ReLU()(x)\n",
    "# x = LSTM(128, return_sequences = True)(x)\n",
    "# x = LayerNormalization()(x)\n",
    "# x = Conv1D(filters=128, kernel_size = 3)(input_layer)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = ReLU()(x)\n",
    "# x = LSTM(64, return_sequences = True)(x)\n",
    "# x = LayerNormalization()(x)\n",
    "# x = LSTM(64, return_sequences = True)(x)\n",
    "# x = LayerNormalization()(x)\n",
    "# x = Conv1D(64, kernel_size = 3)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = ReLU()(x)\n",
    "# x = MaxPooling1D(pool_size=2)(x)\n",
    "# x = LSTM(32, return_sequences=True)(x)\n",
    "# x = LayerNormalization()(x)\n",
    "# x = Conv1D(filters=32, kernel_size=3)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = ReLU()(x)\n",
    "# x = MaxPooling1D(pool_size=2)(x)\n",
    "# x = Flatten()(x)\n",
    "# output_layer = Dense(1, )(x)\n",
    "\n",
    "# model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# model.compile(loss='mean_squared_error', optimizer = RMSprop(learning_rate = 0.002))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "253070c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T04:58:11.019029Z",
     "start_time": "2023-03-02T04:58:11.012214Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform(i, final = 0):\n",
    "    global points, start_point\n",
    "    img = cv2.imread(i)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    lower_red = np.array([0,50,50])\n",
    "    upper_red = np.array([220,255,255])\n",
    "    mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "    res = cv2.bitwise_and(img,img, mask= mask)\n",
    "    BWimg = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY)\n",
    "    cntrs, _ = cv2.findContours(BWimg, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    maxEdge = 0\n",
    "    index = 0\n",
    "    for idx,cntr in enumerate(cntrs):\n",
    "        if len(cntr) > maxEdge:\n",
    "            maxEdge = len(cntr)\n",
    "            index = idx\n",
    "    #     print(f'{idx}. Area of {len(cntr)} vertices:{cv2.contourArea(cntr)}')\n",
    "    d = {}\n",
    "    for i in cntrs[index]:\n",
    "        ele = i[0][0]\n",
    "        if ele not in d:\n",
    "            d[ele] = np.empty((0,1))\n",
    "        d[ele] = np.append(d[ele], i[0][1])\n",
    "    l = np.empty((0,2))\n",
    "    for i in d:\n",
    "        l =  np.append(l, np.array( [[ i,min(d[i]) ]]) , axis=0)\n",
    "    if final > 0:\n",
    "      start_point = max(l[:,0]) - time_step\n",
    "    l = scaler.fit_transform(l)\n",
    "    points = np.append(points, l, axis = 0)\n",
    "#     normalize()\n",
    "\n",
    "def dataset(dataset, time_step):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range (len(dataset)-time_step -1):\n",
    "        X.append(dataset[i:(i+time_step)])\n",
    "        Y.append(dataset[i + time_step])\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b97cb6e-b16d-49ef-b033-eca0ada2436a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(625, 2)\n"
     ]
    }
   ],
   "source": [
    "for i in glob('images/*'):\n",
    "    try:\n",
    "        transform(i)\n",
    "    except:\n",
    "        print(f\"{i.split('/')[-1]} was not able to be loaded\")\n",
    "print(points.shape)\n",
    "corrected_points = points[points[:, 0].argsort()]\n",
    "value = corrected_points[:,1].copy()\n",
    "dummy = scaler.fit_transform(value.reshape(-1,1))\n",
    "dummy = value.copy()\n",
    "df = pd.DataFrame(dummy, columns=['Price'])\n",
    "\n",
    "x_train = np.array(df['Price'].iloc[:-600])\n",
    "X,Y = dataset(np.array(df['Price']), time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73983f97-87a9-49da-852b-25179db012dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 1)]          0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 222, 128)          512       \n",
      "                                                                 \n",
      " layer_normalization (LayerN  (None, 222, 128)         256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 222, 128)          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 222, 128)          131584    \n",
      "                                                                 \n",
      " layer_normalization_1 (Laye  (None, 222, 128)         256       \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 220, 128)          49280     \n",
      "                                                                 \n",
      " layer_normalization_2 (Laye  (None, 220, 128)         256       \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 220, 128)          0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 218, 256)          98560     \n",
      "                                                                 \n",
      " layer_normalization_3 (Laye  (None, 218, 256)         512       \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 218, 256)          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 218, 256)          525312    \n",
      "                                                                 \n",
      " layer_normalization_4 (Laye  (None, 218, 256)         512       \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 216, 256)          196864    \n",
      "                                                                 \n",
      " layer_normalization_5 (Laye  (None, 216, 256)         512       \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 216, 256)          0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 108, 256)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 106, 128)          98432     \n",
      "                                                                 \n",
      " layer_normalization_6 (Laye  (None, 106, 128)         256       \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 106, 128)          0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 106, 128)          131584    \n",
      "                                                                 \n",
      " layer_normalization_7 (Laye  (None, 106, 128)         256       \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 104, 128)          49280     \n",
      "                                                                 \n",
      " layer_normalization_8 (Laye  (None, 104, 128)         256       \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 104, 128)          0         \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 102, 256)          98560     \n",
      "                                                                 \n",
      " layer_normalization_9 (Laye  (None, 102, 256)         512       \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 102, 256)          0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 102, 256)          525312    \n",
      "                                                                 \n",
      " layer_normalization_10 (Lay  (None, 102, 256)         512       \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 100, 256)          196864    \n",
      "                                                                 \n",
      " layer_normalization_11 (Lay  (None, 100, 256)         512       \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 100, 256)          0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 99, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 97, 64)            49216     \n",
      "                                                                 \n",
      " layer_normalization_12 (Lay  (None, 97, 64)           128       \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 97, 64)            0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 97, 64)            33024     \n",
      "                                                                 \n",
      " layer_normalization_13 (Lay  (None, 97, 64)           128       \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 95, 64)            12352     \n",
      "                                                                 \n",
      " layer_normalization_14 (Lay  (None, 95, 64)           128       \n",
      " erNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 95, 64)            0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 94, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6016)              0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 6016)             24064     \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 6017      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,231,809\n",
      "Trainable params: 2,219,777\n",
      "Non-trainable params: 12,032\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2a25c39-edbf-4b2e-a238-8c0fa6c2b750",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"StockVision.h5\", compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b1b90d3-ed1a-4cc4-9836-95556f1038fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "start2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abd9b461-ed49-4c0b-9783-439679b2fd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \n",
      "  Loss: 4.364990000000001\n",
      "Epoch 5 \n",
      "  Loss: 1.0373400000000002\n",
      "Epoch 10 \n",
      "  Loss: 0.16746000000000003\n",
      "Epoch 15 \n",
      "  Loss: 0.6082200000000001\n",
      "Epoch 20 \n",
      "  Loss: 0.24261000000000002\n",
      "Epoch 25 \n",
      "  Loss: 0.15592\n",
      "Epoch 30 \n",
      "  Loss: 0.22309\n",
      "Epoch 35 \n",
      "  Loss: 0.12531\n",
      "Epoch 40 \n",
      "  Loss: 0.23337000000000002\n",
      "Epoch 45 \n",
      "  Loss: 0.15199000000000001\n",
      "Epoch 50 \n",
      "  Loss: 0.10113000000000001\n",
      "Epoch 55 \n",
      "  Loss: 0.11395000000000001\n",
      "Epoch 60 \n",
      "  Loss: 0.09804\n",
      "Epoch 65 \n",
      "  Loss: 0.08264\n",
      "Epoch 70 \n",
      "  Loss: 0.10600000000000001\n",
      "Epoch 75 \n",
      "  Loss: 0.08911000000000001\n",
      "Epoch 80 \n",
      "  Loss: 0.09222000000000001\n",
      "Epoch 85 \n",
      "  Loss: 0.07312\n",
      "Epoch 90 \n",
      "  Loss: 0.07403000000000001\n",
      "Epoch 95 \n",
      "  Loss: 0.08707000000000001\n",
      "Epoch 100 \n",
      "  Loss: 0.0834\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer = RMSprop(learning_rate = 0.001,))\n",
    "history = model.fit(X, Y, epochs = 100, verbose = 0, shuffle=False, callbacks = [Epochs()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3a60f56-236b-4998-904b-9dc7d94daff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "end2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64d7b71c-d551-4136-bcab-06b0713a5435",
   "metadata": {},
   "outputs": [],
   "source": [
    "end1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be13b83d-a5e8-4946-970c-71be65eb8629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train the model: 2402.2500801086426 s\n",
      "Time taken to run the notebook: 2408.7944316864014 s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Time taken to train the model:\\t {end2 - start2}\")\n",
    "print(f\"Time taken to run the notebook:\\t {end1 - start1}\")\n"
    "# model.save("StockVision.h5")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow (AI kit)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
